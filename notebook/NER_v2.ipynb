{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 1\n",
    "\n",
    "Опишите задачу с точки зрения NLP. Что это за задача, какие классические методы существуют для ее решения? Как ее можно решать через LLM? Как обычно оценивают качество моделей в этой задаче?\n",
    "\n",
    "\n",
    "Это задача распознавания именных сущностей(Named entity recognition NER), задача nlp, где мы пытаемся в тексте понять, где находятся имена/номера домов/названия организаций/ и т.д.\n",
    "\n",
    "Классические методы решения NER включают:\n",
    "\n",
    "* Подходы, основанные на правилах: с помощью регулярок/шаблонов/лингвистических признаков.\n",
    "* На основе машинного обучения: Модели, например BERT, обучаются на размеченных данных, чтобы после обучения они сами могли распознавать именованные сущности.\n",
    "* Гибридные подходы: Могут сначала использоваться подходы на основе правил, а после на основе ml для уточнения.\n",
    "\n",
    "Для оценки качества можно использовать метрики, как precision, recall, f-мера\n"
   ],
   "id": "5ae6ea4f6828f359"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 2\n",
    "Реализуйте чтение датасета в pandas DataFrame с обязательными колонками \"document_id\", \"document_text\", \"entity\", \"gold_answer\". "
   ],
   "id": "3b7ffdad32da4a1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from corus import load_bsnlp # я сначала сам пытался прочитать файл, но нашел замечательную либу, которая за меня это сделает)\n",
    "interest_entity = ['PER', 'ORG', 'LOC', 'EVT', 'PRO']\n",
    "path = 'data/' # путь к датасетам\n",
    "doc_id = []\n",
    "doc_text = []\n",
    "entity = []\n",
    "gold_answer = []\n",
    "doc_len = []\n",
    "records = load_bsnlp(path)\n",
    "for record in records:\n",
    "    for ner in record.substrings:\n",
    "        if ner.id.split('-')[0] in interest_entity:\n",
    "            doc_id.append(record.id)\n",
    "            doc_text.append(ner.text)\n",
    "            entity.append(ner.type)\n",
    "            gold_answer.append(ner.id)\n",
    "            doc_len.append(len(record.text))\n",
    "        "
   ],
   "id": "c795ae0859f1e8c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'document_id': doc_id,\n",
    "    'document_text': doc_text,\n",
    "    'entity': entity,\n",
    "    'gold_answer': gold_answer,\n",
    "    'document_lenght': doc_len\n",
    "})\n"
   ],
   "id": "a969707dd715a28d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "d8dad901b4f9a5c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 3\n",
    "Напишите функцию, которая принимает на вход строку??? датафрейма и выдает текст входного сообщения для LLM."
   ],
   "id": "f18996998e8ea003"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def for_llm(document_text):\n",
    "    return f\"\"\"You are a smart and intelligent Named Entity Recognition (NER) system. You need recognize PER, ORG, LOC, EVT, PRO.\n",
    "\n",
    "<Q>Хадимом Хусейном Ризви\n",
    "<A>\n",
    "entity  gold_answer\n",
    "PER     PER-Khadim-Hussain-Rizvi\n",
    "<Q>Facebook\n",
    "<A>\n",
    "entity  gold_answer\n",
    "PRO     PRO-Facebook\n",
    "<Q>Heute\n",
    "<A>\n",
    "entity  gold_answer\n",
    "ORG     ORG-Heute-News\n",
    "<Q>{document_text}\"\"\"\n"
   ],
   "id": "b0ce3ace51a2e6fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llm_text = data['document_text'].apply(for_llm)\n",
    "for i in llm_text:\n",
    "    print()\n",
    "    print(i)\n",
    "    print()"
   ],
   "id": "ed9c228bf38b1eb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 4\n",
    "\n",
    "Получите ответы GigaChat для всех документов. Документов всего 9, поэтому сделать это можно вручную, пользуясь веб-интерфейсом GigaChat или ботом в ВК или Телеграме. Не очищайте историю сообщений, чтобы потом продемонстрировать подлинность ответов на онлайн-собеседовании.\n",
    "Внесите ответы GigaChat в датафрейм, сохраните его.\n"
   ],
   "id": "6843a9adc4145dc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# s = \"\"\"Борис Джонсон\tБорис Джонсон\tPER\tPER-Boris-Johnson\n",
    "# Британии\tВеликобритания\tLOC\tGPE-Great-Britain\n",
    "# Дэвида Дэвиса\tДэвид Дэвис\tPER\tPER-David-Davis\n",
    "# ЕС\tЕС\tORG\tORG-European-Union\n",
    "# Мэй\tМэй\tPER\tPER-Theresa-May\n",
    "# Терезы Мэй\tТереза Мэй\tPER\tPER-Theresa-May\n",
    "# британской прессы\tбританская пресса\tORG\tORG-British-Press\n",
    "# выхода из ЕС\tвыход из ЕС\tEVT\tEVT-Brexit\n",
    "# выхода из Евросоюза\tвыход из Евросоюза\tEVT\tEVT-Brexit\"\"\"\n",
    "# needed = [line.split('\\t')[-1] for line in s.split('\\n')]\n",
    "# needed"
   ],
   "id": "55475c92da5ccc16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Задание 5",
   "id": "c409c77e2568c8d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data['gold_answer'] = data['gold_answer'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "data['giga_pred'] = data['giga_pred'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
   ],
   "id": "e906f1ce352a8160",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def score_fn(gold: str, pred: str) -> float:\n",
    "    gold_entities = [entity for entity in gold.split()]\n",
    "    pred_entities = [entity for entity in pred.split()]\n",
    "    n = 1\n",
    "    precision = sum(1 for pred in pred_entities if pred in gold_entities) / len(pred_entities)\n",
    "    recall = sum(1 for pred in pred_entities if pred in gold_entities) / len(gold_entities)\n",
    "    f_score = ((1 + n**2) * precision * recall)/((n**2 * precision) + recall)\n",
    "    return f_score"
   ],
   "id": "505e97b7ecc16086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Задание 6",
   "id": "1c9e6a54cd5cd763"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scores = data.apply(lambda x: score_fn(x['gold_answer'], x['giga_pred']), axis=1)\n",
    "data['scores'] = scores"
   ],
   "id": "647011d86c022ddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate scores for each row\n",
    "\n",
    "# Group by entity and calculate mean scores\n",
    "entity_scores_mean = scores.groupby(data['gold_answer']).mean()\n",
    "\n",
    "# Group by document and calculate mean scores\n",
    "document_scores_mean = scores.groupby(data.index).mean()\n",
    "\n",
    "# Plot the results\n",
    "plt.bar(entity_scores_mean.index, entity_scores_mean.values)\n",
    "plt.xlabel('Entity')\n",
    "plt.ylabel('Mean Score')\n",
    "plt.title('Score by Entity')"
   ],
   "id": "e81914cf289e9f5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.bar(document_scores_mean.index, document_scores_mean.values)\n",
    "plt.xlabel('Document')\n",
    "plt.ylabel('Mean score')\n",
    "plt.title('Score by document')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "id": "7b828a72bf7972cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Задание 7",
   "id": "11f44d5e9736d7bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of each document\n",
    "doc_lengths = data['document_text'].apply(len)\n",
    "\n",
    "# Plot the scores against doc lengths\n",
    "plt.scatter(doc_lengths, scores)\n",
    "plt.xlabel('Document Length')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ],
   "id": "d1a873417ff2a529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Задание 8",
   "id": "8093fb2ac4d61fc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the number of correct and incorrect answers for each document\n",
    "correct_answers = data['gold_answer'] == data['giga_pred']\n",
    "incorrect_answers = ~correct_answers\n",
    "\n",
    "# Visualize the results\n",
    "plt.bar(data['document_id'], correct_answers.sum(), label='Correct')\n",
    "plt.bar(data['document_id'], incorrect_answers.sum(), label='Incorrect')\n",
    "plt.xlabel('Document ID')\n",
    "plt.ylabel('Number of Answers')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "31998eb0a5902ea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Задание 9\n",
   "id": "77b4df456983e21b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
